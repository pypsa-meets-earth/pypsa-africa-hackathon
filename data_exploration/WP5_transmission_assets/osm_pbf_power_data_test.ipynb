{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script does the following\n",
    "# 1. Downloads OSM files for specified countries from Geofabrik\n",
    "# 2. Filters files for substations and lines\n",
    "# 3. Process and clean data\n",
    "# 4. Exports to CSV\n",
    "# 5. Exports to GeoJson\n",
    "\n",
    "\"\"\"\n",
    "OSM extraction scrpt\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, time\n",
    "#IMPORTANT: RUN SCRIPT FROM THIS SCRIPTS DIRECTORY i.e data_exploration/ TODO: make more robust\n",
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append('../scripts')\n",
    "from iso_country_codes import AFRICA_CC\n",
    "\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# https://gitlab.com/dlr-ve-esy/esy-osmfilter/-/tree/master/\n",
    "from esy.osmfilter import  osm_colors          as CC\n",
    "from esy.osmfilter import run_filter, Node,Way,Relation \n",
    "from esy.osmfilter import export_geojson\n",
    "from esy.osmfilter import osm_info             as osm_info\n",
    "from esy.osmfilter import osm_pickle           as osm_pickle\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geoplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# https://gitlab.com/dlr-ve-esy/esy-osmfilter/-/tree/master/\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig()\n",
    "# logger=logging.getLogger(__name__)\n",
    "# logger.setLevel(logging.INFO)\n",
    "# logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Downloads PBF File for given Country Code\n",
    "\n",
    "def download_pbf(country_code, update):  # update = true forces re-download of files\n",
    "    \"\"\"\n",
    "    TEST ONLY. FROM PYPSA.\n",
    "    Initializes variables for power dispatch for a given component and a\n",
    "    given attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : pypsa.Network\n",
    "    c : str\n",
    "        name of the network component\n",
    "    attr : str\n",
    "        name of the attribute, e.g. 'p'\n",
    "\n",
    "    \"\"\"\n",
    "    country_name = AFRICA_CC[country_code]\n",
    "    # Filename for geofabrik\n",
    "    geofabrik_filename = f'{country_name}-latest.osm.pbf'\n",
    "    # https://download.geofabrik.de/africa/nigeria-latest.osm.pbf\n",
    "    geofabrik_url = f'https://download.geofabrik.de/africa/{geofabrik_filename}'\n",
    "    PBF_inputfile = os.path.join(\n",
    "        os.getcwd(), \"data\", \"osm\", \"pbf\", geofabrik_filename)  # Input filepath\n",
    "\n",
    "    if not os.path.exists(PBF_inputfile) or update is True:\n",
    "        print(f\"{geofabrik_filename} does not exist, downloading to {PBF_inputfile}\")\n",
    "        # create data/osm directory\n",
    "        os.makedirs(os.path.dirname(PBF_inputfile), exist_ok=True)\n",
    "        with requests.get(geofabrik_url, stream=True) as r:\n",
    "            with open(PBF_inputfile, 'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return PBF_inputfile\n",
    "\n",
    "\n",
    "def download_and_filter(country_code, update=False):\n",
    "    PBF_inputfile = download_pbf(country_code, update)\n",
    "\n",
    "    filter_file_exists = False\n",
    "    # json file for the Data dictionary\n",
    "    JSON_outputfile = os.path.join(\n",
    "        os.getcwd(), 'data', 'osm', country_code+'_power.json')\n",
    "    # json file for the Elements dictionary is automatically written to 'data/osm/Elements'+filename)\n",
    "\n",
    "    if os.path.exists(JSON_outputfile):\n",
    "        filter_file_exists = True\n",
    "\n",
    "    # Load Previously Pre-Filtered Files\n",
    "    if update is False and filter_file_exists is True:\n",
    "        create_elements = False  # Do not create elements again\n",
    "        new_prefilter_data = False  # Do not pre-filter data again\n",
    "        # HACKY: esy.osmfilter code to re-create Data.pickle\n",
    "        Data = osm_info.ReadJason(JSON_outputfile, verbose='no')\n",
    "        DataDict = {\"Data\": Data}\n",
    "        osm_pickle.picklesave(DataDict, os.path.realpath(\n",
    "            os.path.join(os.getcwd(), os.path.dirname(JSON_outputfile))))\n",
    "        print(f'Loading Pickle for {AFRICA_CC[country_code]}')  # TODO: Change to Logger\n",
    "    else:\n",
    "        create_elements = True\n",
    "        new_prefilter_data = True\n",
    "        print(f'Creating  New Elements for {AFRICA_CC[country_code]}')  # TODO: Change to Logger\n",
    "\n",
    "    prefilter = {Node: {\"power\": [\"substation\", \"line\",\"generator\"]}, Way: {\n",
    "        \"power\": [\"substation\", \"line\",\"generator\"]}, Relation: {\"power\": [\"substation\", \"line\",\"generator\"]}} #see https://dlr-ve-esy.gitlab.io/esy-osmfilter/filter.html for filter structures\n",
    "    # HACKY: due to esy.osmfilter validation\n",
    "    blackfilter = [(\"\", \"\"), ]\n",
    "\n",
    "    for feature in [\"substation\", \"line\",\"generator\"]:\n",
    "        whitefilter = [[(\"power\", feature), ], ]\n",
    "        elementname = f'{country_code}_{feature}s'\n",
    "\n",
    "        feature_data = run_filter(elementname, PBF_inputfile, JSON_outputfile, prefilter, whitefilter, blackfilter,\n",
    "                                  NewPreFilterData=new_prefilter_data, CreateElements=create_elements, LoadElements=True, verbose=False, multiprocess=True)\n",
    "\n",
    "        if feature == 'substation':\n",
    "            substation_data = feature_data\n",
    "        if feature == 'line':\n",
    "            line_data = feature_data\n",
    "        if feature == 'generator':\n",
    "            generator_data = feature_data\n",
    "\n",
    "    return (substation_data, line_data, generator_data)\n",
    "\n",
    "# Convert Ways to Point Coordinates\n",
    "\n",
    "\n",
    "# TODO: Use shapely and merge with convert_ways_lines\n",
    "def convert_ways_nodes(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    col = \"refs\"\n",
    "    df_way[col] = pd.Series().astype(float) if col not in df_way.columns else df_way[col] #create empty \"refs\" if not in dataframe\n",
    "    for ref in df_way[\"refs\"]:\n",
    "        lonlats = []\n",
    "        for r in ref:\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            lonlats.append(lonlat)\n",
    "        lonlats = np.array(lonlats)\n",
    "        lonlat = np.mean(lonlats, axis=0)  # Hacky Apporx Centroid\n",
    "        lonlat_column.append(lonlat)\n",
    "    df_way.drop('refs', axis=1, inplace=True, errors='ignore')\n",
    "    df_way.insert(0, \"lonlat\", lonlat_column)\n",
    "\n",
    "# Convert Ways to Line Coordinates\n",
    "\n",
    "\n",
    "def convert_ways_lines(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    for ref in df_way[\"refs\"]:  # goes through each row in df_way['refs']\n",
    "        lonlats = []\n",
    "        # picks each element in ref & replaces ID by coordinate tuple (A multiline consist of several points)\n",
    "        for r in ref:\n",
    "            # \"r\" is the ID in Data[\"Node\"], [\"lonlat\"] a list of [x1,y1] (coordinates)\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            lonlat = tuple(lonlat)\n",
    "            lonlats.append(lonlat)  # a list with tuples\n",
    "        lonlat_column.append(lonlats)  # adding a new list of tuples every row\n",
    "    df_way.drop('refs', axis=1, inplace=True)\n",
    "    df_way.insert(1, \"lonlat\", lonlat_column)\n",
    "\n",
    "# Convert Points Pandas Dataframe to GeoPandas Dataframe\n",
    "\n",
    "\n",
    "def convert_pd_to_gdf(df_way):\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df_way, geometry=[Point(x, y) for x, y in df_way.lonlat])\n",
    "    gdf.drop(columns=['lonlat'], inplace=True)\n",
    "    return gdf\n",
    "\n",
    "# Convert Lines Pandas Dataframe to GeoPandas Dataframe\n",
    "\n",
    "\n",
    "def convert_pd_to_gdf_lines(df_way, simplified=False):\n",
    "    df_way['geometry'] = df_way['lonlat'].apply(lambda x: LineString(x))\n",
    "    if simplified is True:\n",
    "        df_way['geometry'] = df_way['geometry'].apply(lambda x: x.simplify(0.005, preserve_topology=False))\n",
    "    gdf = gpd.GeoDataFrame(df_way, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    gdf.drop(columns=['lonlat'], inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# Convert Filtered Data, Elements to Pandas Dataframes\n",
    "\n",
    "\n",
    "def convert_filtered_data_to_dfs(country_code, feature_data, feature):\n",
    "    [Data, Elements] = feature_data\n",
    "    elementname = f'{country_code}_{feature}s'\n",
    "    df_way = pd.json_normalize(Elements[elementname][\"Way\"].values())\n",
    "    df_node = pd.json_normalize(Elements[elementname][\"Node\"].values())\n",
    "    return (df_node, df_way, Data)\n",
    "\n",
    "\n",
    "def process_substation_data(country_code, substation_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(country_code, substation_data, 'substation')\n",
    "    convert_ways_nodes(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_node['Type'] = 'Node'\n",
    "    df_way['Type'] = 'Way'\n",
    "\n",
    "    df_combined = pd.concat([df_node, df_way], axis=0)\n",
    "    # Add Country Column\n",
    "    df_combined['Country'] = AFRICA_CC[country_code]\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "def process_line_data(country_code, line_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(country_code, line_data, 'line')\n",
    "    convert_ways_lines(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_way['Type'] = 'Way'\n",
    "\n",
    "    # Add Country Column\n",
    "    df_way['Country'] = AFRICA_CC[country_code]\n",
    "    return df_way\n",
    "\n",
    "\n",
    "def process_generator_data(country_code, generator_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(country_code, generator_data, 'generator')\n",
    "    convert_ways_nodes(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_node['Type'] = 'Node'\n",
    "    df_way['Type'] = 'Way'\n",
    "\n",
    "    df_combined = pd.concat([df_node, df_way], axis=0)\n",
    "    # Add Country Column\n",
    "    df_combined['Country'] = AFRICA_CC[country_code]\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    df_all_substations = pd.DataFrame()\n",
    "    df_all_lines = pd.DataFrame()\n",
    "    df_all_generators = pd.DataFrame()\n",
    "    # test_CC = {\"NG\": \"nigeria\"}\n",
    "    for country_code in AFRICA_CC.keys():\n",
    "        substation_data, line_data, generator_data = download_and_filter(country_code)\n",
    "        for feature in [\"substation\", \"line\",\"generator\"]:\n",
    "            if feature == 'substation':\n",
    "                df_substation = process_substation_data(country_code, substation_data)\n",
    "                df_all_substations = pd.concat(\n",
    "                    [df_all_substations, df_substation])\n",
    "            if feature == 'line':\n",
    "                df_line = process_line_data(country_code, line_data)\n",
    "                df_all_lines = pd.concat([df_all_lines, df_line])\n",
    "            if feature == 'generator':\n",
    "                df_generator = process_generator_data(country_code, generator_data)\n",
    "                df_all_generators = pd.concat(\n",
    "                    [df_all_generators, df_generator])\n",
    "    \n",
    "    #----------- SUBSTATIONS -----------\n",
    "\n",
    "    # Clean\n",
    "    df_all_substations.reset_index(drop=True, inplace=True)\n",
    "    df_all_substations.dropna(subset=['tags.voltage'], inplace = True) # Drop any substations with Voltage = N/A\n",
    "    df_all_substations.dropna(thresh=len(df_all_substations)*0.25, axis=1, how='all', inplace = True) #Drop Columns with 75% values as N/A\n",
    "\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_substations.')\n",
    "    df_all_substations.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "    gdf_substations = convert_pd_to_gdf(df_all_substations)\n",
    "    gdf_substations.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson\n",
    "\n",
    "\n",
    "    # ----------- LINES -----------\n",
    "\n",
    "    # Clean\n",
    "    # TODO: FIX Voltage Filter\n",
    "    # Some transmission lines carry multiple voltages, having voltage_V = 10000;20000  (two lines)\n",
    "    # The following code keeps only the first information before the semicolon..\n",
    "    # Needs to be corrected in future, creating two lines with the same bus ID.\n",
    "    \n",
    "    df_all_lines.reset_index(drop=True, inplace=True)\n",
    "    df_all_lines.dropna(subset=['tags.voltage'], inplace = True) # Drop any lines with Voltage = N/A\n",
    "    df_all_lines.rename(columns = {'tags.voltage':\"voltage_V\"}, inplace = True) \n",
    "    df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split('*').str[0]\n",
    "    df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split(';').str[0]\n",
    "    df_all_lines['voltage_V'] = df_all_lines['voltage_V'].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna() ## if cell can't converted to float -> drop\n",
    "    df_all_lines = df_all_lines[df_all_lines.voltage_V > 10000]\n",
    "    df_all_lines.dropna(thresh=len(df_all_lines)*0.25, axis=1, how='all', inplace=True) # Drop Columns with 75% values as N/A\n",
    "\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(os.getcwd(), 'data', 'africa_all'+'_lines.')  \n",
    "    df_all_lines.to_csv(outputfile_partial + 'csv')  # Generate CSV\n",
    "    gdf_lines = convert_pd_to_gdf_lines(df_all_lines, simplified=True)\n",
    "    gdf_lines.to_file(outputfile_partial+'geojson',\n",
    "                driver=\"GeoJSON\")  # Generate GeoJson\n",
    "\n",
    "\n",
    "    # ----------- Generator -----------\n",
    "    \n",
    "    df_all_generators.reset_index(drop=True, inplace=True)\n",
    "    df_all_generators.drop(columns = [\"tags.fixme\",\"tags.frequency\",\"tags.name:ar\",\"tags.building\",\"tags.barrier\"], inplace = True, errors='ignore')\n",
    "    df_all_generators = df_all_generators[df_all_generators['tags.generator:output:electricity'].astype(str).str.contains('MW')] #removes boolean \n",
    "    df_all_generators['tags.generator:output:electricity'] = df_all_generators['tags.generator:output:electricity'].str.extract('(\\d+)').astype(float)\n",
    "    df_all_generators.rename(columns = {'tags.generator:output:electricity':\"power_output_MW\"}, inplace = True)\n",
    "    df_all_generators.dropna(thresh=len(df_all_generators)*0.25, axis=1, how='all', inplace=True) # Drop Columns with 75% values as N/A\n",
    "\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_generators.')\n",
    "    df_all_generators.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "    gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "    gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pickle for nigeria\n"
     ]
    }
   ],
   "source": [
    "df_all_substations = pd.DataFrame()\n",
    "df_all_lines = pd.DataFrame()\n",
    "df_all_generators = pd.DataFrame()\n",
    "test_CC = {\"NG\": \"nigeria\"}\n",
    "for country_code in test_CC.keys():\n",
    "    substation_data, line_data, generator_data = download_and_filter(country_code)\n",
    "    for feature in [\"substation\", \"line\",\"generator\"]:\n",
    "        if feature == 'substation':\n",
    "            df_substation = process_substation_data(country_code, substation_data)\n",
    "            df_all_substations = pd.concat(\n",
    "                [df_all_substations, df_substation])\n",
    "        if feature == 'line':\n",
    "            df_line = process_line_data(country_code, line_data)\n",
    "            df_all_lines = pd.concat([df_all_lines, df_line])\n",
    "        if feature == 'generator':\n",
    "            df_generator = process_generator_data(country_code, generator_data)\n",
    "            df_all_generators = pd.concat(\n",
    "                [df_all_generators, df_generator])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- SUBSTATIONS -----------\n",
    "\n",
    "# Clean\n",
    "df_all_substations.reset_index(drop=True, inplace=True)\n",
    "df_all_substations.dropna(subset=['tags.voltage'], inplace = True) # Drop any substations with Voltage = N/A\n",
    "df_all_substations.dropna(thresh=len(df_all_substations)*0.25, axis=1, how='all', inplace = True) #Drop Columns with 75% values as N/A\n",
    "df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='industrial'].index, inplace=True)\n",
    "df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='distribution'].index, inplace=True)\n",
    "\n",
    "# Generate Files\n",
    "outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_substations.')\n",
    "df_all_substations.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "gdf_substations = convert_pd_to_gdf(df_all_substations)\n",
    "gdf_substations.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Generator -----------\n",
    "\n",
    "df_all_generators.reset_index(drop=True, inplace=True)\n",
    "df_all_generators.drop(columns = [\"tags.fixme\",\"tags.frequency\",\"tags.name:ar\",\"tags.building\",\"tags.barrier\"], inplace = True, errors='ignore')\n",
    "df_all_generators = df_all_generators[df_all_generators['tags.generator:output:electricity'].astype(str).str.contains('MW')] #removes boolean \n",
    "df_all_generators['tags.generator:output:electricity'] = df_all_generators['tags.generator:output:electricity'].str.extract('(\\d+)').astype(float)\n",
    "df_all_generators.rename(columns = {'tags.generator:output:electricity':\"power_output_MW\"}, inplace = True)\n",
    "df_all_generators.dropna(thresh=len(df_all_generators)*0.25, axis=1, how='all', inplace=True) # Drop Columns with 75% values as N/A\n",
    "\n",
    "# Generate Files\n",
    "outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_generators.')\n",
    "df_all_generators.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ways_lines(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    \n",
    "    for ref in df_way[\"refs\"]:  # goes through each row in df_way['refs']\n",
    "        lonlats = []\n",
    "        # picks each element in ref & replaces ID by coordinate tuple (A multiline consist of several points)\n",
    "        for r in ref:\n",
    "            # \"r\" is the ID in Data[\"Node\"], [\"lonlat\"] a list of [x1,y1] (coordinates)\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            lonlat = tuple(lonlat)\n",
    "            lonlats.append(lonlat)  # a list with tuples\n",
    "        lonlat_column.append(lonlats)  # adding a new list of tuples every row\n",
    "    # df_way.drop('refs', axis=1, inplace=True)\n",
    "    df_way.insert(1, \"lonlat\", lonlat_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line_data(country_code, line_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(country_code, line_data, 'line')\n",
    "    convert_ways_lines(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_way['Type'] = 'Way'\n",
    "\n",
    "    # Add Country Column\n",
    "    df_way['Country'] = AFRICA_CC[country_code]\n",
    "    return df_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- LINES -----------\n",
    "\n",
    "# Clean\n",
    "# TODO: FIX Voltage Filter\n",
    "# Some transmission lines carry multiple voltages, having voltage_V = 10000;20000  (two lines)\n",
    "# The following code keeps only the first information before the semicolon..\n",
    "# Needs to be corrected in future, creating two lines with the same bus ID.\n",
    "\n",
    "df_all_lines.reset_index(drop=True, inplace=True)\n",
    "df_all_lines.dropna(subset=['tags.voltage'], inplace = True) # Drop any lines with Voltage = N/A\n",
    "df_all_lines.rename(columns = {'tags.voltage':\"voltage_V\"}, inplace = True) \n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split('*').str[0]\n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split(';').str[0]\n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna() ## if cell can't converted to float -> drop\n",
    "df_all_lines = df_all_lines[df_all_lines.voltage_V > 10000]\n",
    "df_all_lines.dropna(thresh=len(df_all_lines)*0.25, axis=1, how='all', inplace=True) # Drop Columns with 75% values as N/A\n",
    "# df_all_lines['end_refs'] = \n",
    "\n",
    "# Generate Files\n",
    "# outputfile_partial = os.path.join(os.getcwd(), 'data', 'africa_all'+'_lines.')  \n",
    "# df_all_lines.to_csv(outputfile_partial + 'csv')  # Generate CSV\n",
    "# gdf_lines = convert_pd_to_gdf_lines(df_all_lines, simplified=True)\n",
    "# gdf_lines.to_file(outputfile_partial+'geojson',\n",
    "#             driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>lonlat</th>\n      <th>refs</th>\n      <th>tags.power</th>\n      <th>tags.cables</th>\n      <th>tags.frequency</th>\n      <th>voltage_V</th>\n      <th>Type</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>556530547</td>\n      <td>[(12.03563570000005, 9.471879900000054), (12.0...</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>line</td>\n      <td>3</td>\n      <td>50</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>671706473</td>\n      <td>[(6.6724670000000135, 6.1823994999999785), (6....</td>\n      <td>[6290115060, 6290115059, 6290115058, 629011505...</td>\n      <td>line</td>\n      <td>3</td>\n      <td>50</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>108020973</td>\n      <td>[(3.2462319000002138, 6.603543000000252), (3.2...</td>\n      <td>[5198712394, 3064004782, 3064004786, 306400479...</td>\n      <td>line</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>671606207</td>\n      <td>[(5.642713300000001, 5.923880100000009), (5.64...</td>\n      <td>[5282666532, 6289294708, 5282666526]</td>\n      <td>line</td>\n      <td>3</td>\n      <td>50</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>575700599</td>\n      <td>[(6.83858290000003, 6.128648600000032), (6.843...</td>\n      <td>[5448403687, 5448403686]</td>\n      <td>line</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>563719558</td>\n      <td>[(6.3848537000000105, 7.516805099999982), (6.3...</td>\n      <td>[5432136688, 5432136687, 5432136686, 543213668...</td>\n      <td>line</td>\n      <td>3</td>\n      <td>50</td>\n      <td>132000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>649</th>\n      <td>565151711</td>\n      <td>[(7.844407300000021, 12.551450599999956), (7.8...</td>\n      <td>[5443838099, 5443838095, 5443838091, 544383809...</td>\n      <td>line</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>132000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>669957218</td>\n      <td>[(3.615386300000014, 6.566526399999998), (3.61...</td>\n      <td>[6274221446, 6274221432, 6274221440, 627422144...</td>\n      <td>line</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>564385545</td>\n      <td>[(7.231026300000037, 9.153350900000015), (7.23...</td>\n      <td>[5437840807, 6291806172, 6291806173, 629180617...</td>\n      <td>line</td>\n      <td>6</td>\n      <td>50</td>\n      <td>330000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>695800745</td>\n      <td>[(5.339799400000043, 6.634346600000014), (5.34...</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>line</td>\n      <td>6</td>\n      <td>50</td>\n      <td>132000</td>\n      <td>Way</td>\n      <td>nigeria</td>\n    </tr>\n  </tbody>\n</table>\n<p>453 rows Ã— 9 columns</p>\n</div>",
      "text/plain": "            id                                             lonlat  \\\n2    556530547  [(12.03563570000005, 9.471879900000054), (12.0...   \n3    671706473  [(6.6724670000000135, 6.1823994999999785), (6....   \n6    108020973  [(3.2462319000002138, 6.603543000000252), (3.2...   \n7    671606207  [(5.642713300000001, 5.923880100000009), (5.64...   \n8    575700599  [(6.83858290000003, 6.128648600000032), (6.843...   \n..         ...                                                ...   \n647  563719558  [(6.3848537000000105, 7.516805099999982), (6.3...   \n649  565151711  [(7.844407300000021, 12.551450599999956), (7.8...   \n650  669957218  [(3.615386300000014, 6.566526399999998), (3.61...   \n651  564385545  [(7.231026300000037, 9.153350900000015), (7.23...   \n652  695800745  [(5.339799400000043, 6.634346600000014), (5.34...   \n\n                                                  refs tags.power tags.cables  \\\n2    [2725719269, 2725912800, 2725719240, 272571923...       line           3   \n3    [6290115060, 6290115059, 6290115058, 629011505...       line           3   \n6    [5198712394, 3064004782, 3064004786, 306400479...       line           3   \n7                 [5282666532, 6289294708, 5282666526]       line           3   \n8                             [5448403687, 5448403686]       line         NaN   \n..                                                 ...        ...         ...   \n647  [5432136688, 5432136687, 5432136686, 543213668...       line           3   \n649  [5443838099, 5443838095, 5443838091, 544383809...       line         NaN   \n650  [6274221446, 6274221432, 6274221440, 627422144...       line           6   \n651  [5437840807, 6291806172, 6291806173, 629180617...       line           6   \n652  [6533692645, 6533692646, 6533692647, 653369264...       line           6   \n\n    tags.frequency  voltage_V Type  Country  \n2               50     330000  Way  nigeria  \n3               50     330000  Way  nigeria  \n6              NaN     330000  Way  nigeria  \n7               50     330000  Way  nigeria  \n8              NaN     330000  Way  nigeria  \n..             ...        ...  ...      ...  \n647             50     132000  Way  nigeria  \n649            NaN     132000  Way  nigeria  \n650            NaN     330000  Way  nigeria  \n651             50     330000  Way  nigeria  \n652             50     132000  Way  nigeria  \n\n[453 rows x 9 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_line_lookup = df_all_lines[['id','refs']]\n",
    "display(df_all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pypsa': conda)",
   "name": "python3710jvsc74a57bd09a6789bfb301b77bab315636af11818455845432a243e82ed991667bc6cd3910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}